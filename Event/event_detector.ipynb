{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from movienet.tools import ActionExtractor, PersonDetector, PersonExtractor\r\n",
    "\r\n",
    "import cv2 as cv\r\n",
    "import numpy as np\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "import json\r\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "act = ActionExtractor(require_normalized_bbox=False)\r\n",
    "psd = PersonDetector()\r\n",
    "\r\n",
    "action_raw= { \"name\": \"bend/bow (at the waist)\" ,\"_id\": 1 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"crawl\" ,\"_id\": 2 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"crouch/kneel\" ,\"_id\": 3 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"dance\" ,\"_id\": 4 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"fall down\" ,\"_id\": 5 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"get up\" ,\"_id\": 6 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"jump/leap\" ,\"_id\": 7 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"lie/sleep\" ,\"_id\": 8 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"martial art\" ,\"_id\": 9 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"run/jog\" ,\"_id\": 10 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"sit\" ,\"_id\": 11 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"stand\" ,\"_id\": 12 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"swim\" ,\"_id\": 13 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"walk\" ,\"_id\": 14 ,\"_type\": \"PERSON_MOVEMENT\" } , { \"name\": \"answer phone\" ,\"_id\": 15 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"brush teeth\" ,\"_id\": 16 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"carry/hold (an object)\" ,\"_id\": 17 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"catch (an object)\" ,\"_id\": 18 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"chop\" ,\"_id\": 19 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"climb (e.g., a mountain)\" ,\"_id\": 20 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"clink glass\" ,\"_id\": 21 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"close (e.g., a door, a box)\" ,\"_id\": 22 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"cook\" ,\"_id\": 23 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"cut\" ,\"_id\": 24 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"dig\" ,\"_id\": 25 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"dress/put on clothing\" ,\"_id\": 26 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"drink\" ,\"_id\": 27 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"drive (e.g., a car, a truck)\" ,\"_id\": 28 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"eat\" ,\"_id\": 29 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"enter\" ,\"_id\": 30 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"exit\" ,\"_id\": 31 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"extract\" ,\"_id\": 32 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"fishing\" ,\"_id\": 33 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"hit (an object)\" ,\"_id\": 34 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"kick (an object)\" ,\"_id\": 35 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"lift/pick up\" ,\"_id\": 36 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"listen (e.g., to music)\" ,\"_id\": 37 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"open (e.g., a window, a car door)\" ,\"_id\": 38 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"paint\" ,\"_id\": 39 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"play board game\" ,\"_id\": 40 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"play musical instrument\" ,\"_id\": 41 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"play with pets\" ,\"_id\": 42 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"point to (an object)\" ,\"_id\": 43 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"press\" ,\"_id\": 44 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"pull (an object)\" ,\"_id\": 45 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"push (an object)\" ,\"_id\": 46 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"put down\" ,\"_id\": 47 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"read\" ,\"_id\": 48 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"ride (e.g., a bike, a car, a horse)\" ,\"_id\": 49 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"row boat\" ,\"_id\": 50 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"sail boat\" ,\"_id\": 51 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"shoot\" ,\"_id\": 52 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"shovel\" ,\"_id\": 53 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"smoke\" ,\"_id\": 54 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"stir\" ,\"_id\": 55 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"take a photo\" ,\"_id\": 56 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"text on/look at a cellphone\" ,\"_id\": 57 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"throw\" ,\"_id\": 58 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"touch (an object)\" ,\"_id\": 59 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"turn (e.g., a screwdriver)\" ,\"_id\": 60 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"watch (e.g., TV)\" ,\"_id\": 61 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"work on a computer\" ,\"_id\": 62 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"write\" ,\"_id\": 63 ,\"_type\": \"OBJECT_MANIPULATION\" } , { \"name\": \"fight/hit (a person)\" ,\"_id\": 64 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"give/serve (an object) to (a person)\" ,\"_id\": 65 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"grab (a person)\" ,\"_id\": 66 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"hand clap\" ,\"_id\": 67 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"hand shake\" ,\"_id\": 68 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"hand wave\" ,\"_id\": 69 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"hug (a person)\" ,\"_id\": 70 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"kick (a person)\" ,\"_id\": 71 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"kiss (a person)\" ,\"_id\": 72 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"lift (a person)\" ,\"_id\": 73 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"listen to (a person)\" ,\"_id\": 74 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"play with kids\" ,\"_id\": 75 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"push (another person)\" ,\"_id\": 76 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"sing to (e.g., self, a person, a group)\" ,\"_id\": 77 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"take (an object) from (a person)\" ,\"_id\": 78 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"talk to (e.g., self, a person, a group)\" ,\"_id\": 79 ,\"_type\": \"PERSON_INTERACTION\" } , { \"name\": \"watch (a person)\" ,\"_id\": 80 ,\"_type\": \"PERSON_INTERACTION\" }\r\n",
    "\r\n",
    "action_label = []\r\n",
    "\r\n",
    "for action in action_raw:\r\n",
    "    action_label.append(action[\"name\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Use load_from_local loader\n",
      "Use load_from_local loader\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cap = cv.VideoCapture(\"One man band.mp4\")\r\n",
    "total_frames = cap.get(cv.CAP_PROP_FRAME_COUNT)\r\n",
    "\r\n",
    "total_data_result = []\r\n",
    "last_frame = -1\r\n",
    "try:\r\n",
    "    result_file = open(\"one_man_band_events.json\", \"r\")\r\n",
    "    total_data_result = json.load(result_file)\r\n",
    "    result_file.close()\r\n",
    "\r\n",
    "    last_frame = total_data_result[-1][\"frame\"]\r\n",
    "except:\r\n",
    "    pass\r\n",
    "\r\n",
    "\r\n",
    "total_time = 0\r\n",
    "start_tick = cv.getTickCount()\r\n",
    "\r\n",
    "for i in range(last_frame+1, int(total_frames)):\r\n",
    "    start_frame_tick = cv.getTickCount()\r\n",
    "    \r\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, i)\r\n",
    "    ret, frame = cap.read()\r\n",
    "\r\n",
    "    result = {\"frame\":i}\r\n",
    "\r\n",
    "    person_bbox = psd.detect(frame)\r\n",
    "    \r\n",
    "    if person_bbox.shape[0] > 0:\r\n",
    "        result[\"person\"] = person_bbox.tolist()\r\n",
    "\r\n",
    "        action_result = act.extract([frame], person_bbox)\r\n",
    "\r\n",
    "        result[\"action\"] = []\r\n",
    "\r\n",
    "        for j in range(person_bbox.shape[0]):\r\n",
    "            action = action_label[np.argmax(action_result[j][\"score\"])]\r\n",
    "            result[\"action\"].append(action)\r\n",
    "    \r\n",
    "    total_data_result.append(result)\r\n",
    "\r\n",
    "    end_frame_tick = cv.getTickCount()\r\n",
    "    frame_time = (end_frame_tick - start_frame_tick) / cv.getTickFrequency()\r\n",
    "    total_time += frame_time\r\n",
    "    mean_time = total_time / (i - last_frame)\r\n",
    "\r\n",
    "    if i % 100 == 0 or i == last_frame+1:\r\n",
    "        print(i, \"frames completed,\", i/total_frames*100, \"%\", mean_time, \"sec/frame\", mean_time*(total_frames-i)/60, \"min to go\")\r\n",
    "\r\n",
    "\r\n",
    "end_tick = cv.getTickCount()\r\n",
    "\r\n",
    "print(\"time =\", (end_tick - start_tick) / cv.getTickFrequency())\r\n",
    "\r\n",
    "\r\n",
    "result_file = open(\"one_man_band_events.json\", \"w\")\r\n",
    "json.dump(total_data_result, result_file)\r\n",
    "result_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "result_file = open(\"one_man_band_events.json\", \"r\")\r\n",
    "total_data_result = json.load(result_file)\r\n",
    "result_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "source": [
    "cap = cv.VideoCapture(\"One man band.mp4\")\r\n",
    "total_frames = cap.get(cv.CAP_PROP_FRAME_COUNT)\r\n",
    "\r\n",
    "for i in range(int(total_frames)):\r\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, i)\r\n",
    "    ret, frame = cap.read()\r\n",
    "\r\n",
    "    if \"person\" in total_data_result[i]:\r\n",
    "        for j in range(len(total_data_result[i][\"person\"])):\r\n",
    "            bbox = np.array(total_data_result[i][\"person\"][j], int)\r\n",
    "            cv.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\r\n",
    "            \r\n",
    "            action = total_data_result[i][\"action\"][j]\r\n",
    "            cv.putText(frame, action, (bbox[0],bbox[1]), cv.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0),2,cv.LINE_AA)\r\n",
    "\r\n",
    "    \r\n",
    "    \r\n",
    "    cv.imshow(\"frame\", frame)\r\n",
    "    if cv.waitKey(1) == ord('q'):\r\n",
    "        break\r\n",
    "\r\n",
    "cv.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def intersection_over_union(bbox1, bbox2):\r\n",
    "    area1 = abs((bbox1[2]-bbox1[0]) * (bbox1[3]-bbox1[1]))\r\n",
    "    area2 = abs((bbox2[2]-bbox2[0]) * (bbox2[3]-bbox2[1]))\r\n",
    "    \r\n",
    "    inter_x = max(bbox1[0], bbox2[0]) - min(bbox1[2], bbox2[2])\r\n",
    "    inter_y = max(bbox1[1], bbox2[1]) - min(bbox1[3], bbox2[3])\r\n",
    "    inter_area = inter_x*inter_y\r\n",
    "\r\n",
    "    union_area = area1+area2 - inter_area\r\n",
    "   \r\n",
    "    return inter_area/union_area\r\n",
    "     "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sort import *\r\n",
    "\r\n",
    "tracker = Sort()\r\n",
    "\r\n",
    "tracked_bbox = {}\r\n",
    "\r\n",
    "for i in range(int(total_frames)):\r\n",
    "    frame_index = total_data_result[i][\"frame\"]\r\n",
    "\r\n",
    "    if \"person\" in total_data_result[i]:\r\n",
    "        track_bbs_ids = tracker.update(np.array(total_data_result[i][\"person\"]))\r\n",
    "    else:\r\n",
    "        track_bbs_ids = tracker.update()\r\n",
    "        pass\r\n",
    "    \r\n",
    "    for j in range(track_bbs_ids.shape[0]):\r\n",
    "        if not track_bbs_ids[j][4] in tracked_bbox:\r\n",
    "            tracked_bbox[track_bbs_ids[j][4]] = {\"action\":[]}\r\n",
    "        tracked_bbox[track_bbs_ids[j][4]][frame_index] = {}\r\n",
    "        tracked_bbox[track_bbs_ids[j][4]][frame_index][\"bounding_box\"] = track_bbs_ids[j][:4]\r\n",
    "        tracked_bbox[track_bbs_ids[j][4]][frame_index][\"action\"] = []\r\n",
    "\r\n",
    "\r\n",
    "        for k in range(len( total_data_result[i][\"person\"])):\r\n",
    "            if intersection_over_union(track_bbs_ids[j][:4], total_data_result[i][\"person\"][k]) > 0.8:\r\n",
    "                tracked_bbox[track_bbs_ids[j][4]][frame_index][\"action\"].append(total_data_result[i][\"action\"][k])\r\n",
    "                tracked_bbox[track_bbs_ids[j][4]][\"action\"].append(total_data_result[i][\"action\"][k])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "source": [
    "cap = cv.VideoCapture(\"One man band.mp4\")\r\n",
    "total_frames = cap.get(cv.CAP_PROP_FRAME_COUNT)\r\n",
    "\r\n",
    "for i in range(int(total_frames)):\r\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, i)\r\n",
    "    ret, frame = cap.read()\r\n",
    "\r\n",
    "    for actor_id in tracked_bbox:\r\n",
    "        if i in tracked_bbox[actor_id]:\r\n",
    "            bbox = tracked_bbox[actor_id][i][\"bounding_box\"].astype(int)\r\n",
    "            cv.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\r\n",
    "            \r\n",
    "\r\n",
    "            actions, counts = np.unique(tracked_bbox[actor_id][\"action\"], return_counts=True)\r\n",
    "            text = actions[np.argmax(counts)] \r\n",
    "\r\n",
    "            cv.putText(frame, text, (bbox[0],bbox[1]), cv.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0),2,cv.LINE_AA)\r\n",
    "    \r\n",
    "    cv.imshow(\"frame\", cv.resize(frame, (1920//2, 1080//2)))\r\n",
    "    if cv.waitKey(1) == ord('q'):\r\n",
    "        break\r\n",
    "        \r\n",
    "        \r\n",
    "cv.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from movienet.tools.detector.persondetector import resources_dir\r\n",
    "import ntpath\r\n",
    "\r\n",
    "weight_path = ntpath.join(resources_dir, 'resnet50_csm.pth')\r\n",
    "\r\n",
    "extractor = PersonExtractor(weight_path)\r\n",
    "\r\n",
    "\r\n",
    "actors_feat = np.ndarray((3,256), np.float32)\r\n",
    "for i in range(3):\r\n",
    "    actor_img = cv.imread(\"actor\"+str(i+1)+\".png\")\r\n",
    "    feat = extractor.extract(actor_img)\r\n",
    "\r\n",
    "    feat /= np.linalg.norm(feat)\r\n",
    "\r\n",
    "    actors_feat[i] = feat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "source": [
    "match_matrix = np.ndarray((3,3))\r\n",
    "\r\n",
    "for i in range(3):\r\n",
    "    for j in range(3):\r\n",
    "        match_matrix[i][j] = actors_feat[i].dot(actors_feat[j])\r\n",
    "\r\n",
    "print(match_matrix)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.99999994 0.60234237 0.59941274]\n",
      " [0.60234237 0.99999994 0.6182273 ]\n",
      " [0.59941274 0.6182273  1.        ]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "cap = cv.VideoCapture(\"One man band.mp4\")\r\n",
    "total_frames = cap.get(cv.CAP_PROP_FRAME_COUNT)\r\n",
    "\r\n",
    "for actor_id in list(tracked_bbox.keys()):\r\n",
    "    n_score = 0\r\n",
    "    scores = np.zeros(3)\r\n",
    "    \r\n",
    "    frame_index = list(tracked_bbox[actor_id].keys())[1]\r\n",
    "    for frame_index in list(tracked_bbox[actor_id].keys())[1:]:\r\n",
    "\r\n",
    "        cap.set(cv.CAP_PROP_POS_FRAMES, frame_index)\r\n",
    "        ret, frame = cap.read()\r\n",
    "\r\n",
    "        bbox = tracked_bbox[actor_id][frame_index][\"bounding_box\"]\r\n",
    "        bbox[bbox<0] = 0\r\n",
    "\r\n",
    "        mask = frame[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\r\n",
    "\r\n",
    "        mask_feature = extractor.extract(mask)\r\n",
    "        mask_feature /= np.linalg.norm(mask_feature)\r\n",
    "\r\n",
    "        for i in range(3):\r\n",
    "            scores[i] += actors_feat[i].dot(mask_feature)\r\n",
    "\r\n",
    "        n_score += 1\r\n",
    "\r\n",
    "    scores /= n_score\r\n",
    "    actor_index = np.argmax(scores)\r\n",
    "    actor_score = scores[actor_index]\r\n",
    "\r\n",
    "    tracked_bbox[actor_id][\"actor_id\"] = actor_index\r\n",
    "    tracked_bbox[actor_id][\"score\"] = actor_score\r\n",
    "    tracked_bbox[actor_id][\"scores\"] = scores\r\n",
    "\r\n",
    "\r\n",
    "    if actor_score < 0.65:\r\n",
    "        del tracked_bbox[actor_id]\r\n",
    "        pass\r\n",
    "\r\n",
    "cap.release()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "final_result = {0:{}, 1:{}, 2:{}}\r\n",
    "\r\n",
    "for actor_id in tracked_bbox:\r\n",
    "    real_actor_id = tracked_bbox[actor_id][\"actor_id\"]\r\n",
    "    score = tracked_bbox[actor_id][\"score\"]\r\n",
    "\r\n",
    "    frames_index = list(tracked_bbox[actor_id].keys())[1:]\r\n",
    "    frames_index.remove(\"actor_id\")\r\n",
    "    frames_index.remove('score')\r\n",
    "    frames_index.remove('scores')\r\n",
    "\r\n",
    "    actions, counts = np.unique(tracked_bbox[actor_id][\"action\"], return_counts=True)\r\n",
    "    action = actions[np.argmax(counts)] \r\n",
    "\r\n",
    "    for index in frames_index:\r\n",
    "        data = tracked_bbox[actor_id][index]\r\n",
    "        data[\"actor_score\"] = score\r\n",
    "        data[\"action\"] = action\r\n",
    "\r\n",
    "        if index in final_result[real_actor_id]:\r\n",
    "            if final_result[real_actor_id][index][\"actor_score\"] < score:\r\n",
    "                final_result[real_actor_id][index] = data\r\n",
    "        else:\r\n",
    "            final_result[real_actor_id][index] = data\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "cap = cv.VideoCapture(\"One man band.mp4\")\r\n",
    "total_frames = cap.get(cv.CAP_PROP_FRAME_COUNT)\r\n",
    "\r\n",
    "for i in range(int(total_frames)):\r\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, i)\r\n",
    "    ret, frame = cap.read()\r\n",
    "\r\n",
    "    for actor_id in final_result:\r\n",
    "        if i in final_result[actor_id]:\r\n",
    "            bbox = final_result[actor_id][i][\"bounding_box\"].astype(int)\r\n",
    "            cv.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2) \r\n",
    "\r\n",
    "            actor_text = str(actor_id)+ \" \" +\"{0:.2f}\".format(final_result[actor_id][i][\"actor_score\"])\r\n",
    "\r\n",
    "            action_text = final_result[actor_id][i][\"action\"]\r\n",
    "            \r\n",
    "            cv.putText(frame, actor_text, (bbox[0],bbox[1]), cv.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0),2,cv.LINE_AA)\r\n",
    "            cv.putText(frame, action_text, (bbox[0],bbox[3]), cv.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0),2,cv.LINE_AA)\r\n",
    "    \r\n",
    "    cv.imshow(\"frame\", cv.resize(frame, (1920//2, 1080//2)))\r\n",
    "    \r\n",
    "    if cv.waitKey(1) == ord('q'):\r\n",
    "        break\r\n",
    "        \r\n",
    "        \r\n",
    "cv.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "source": [
    "def encoder(obj):\r\n",
    "    if isinstance(obj, np.integer):\r\n",
    "        return int(obj)\r\n",
    "    elif isinstance(obj, np.floating):\r\n",
    "        return float(obj)\r\n",
    "    elif isinstance(obj, np.ndarray):\r\n",
    "        return obj.tolist()\r\n",
    "    \r\n",
    "    return obj.__dict__\r\n",
    "\r\n",
    "result_file = open(\"one_man_band_events_filtered.json\", \"w\")\r\n",
    "json.dump(final_result, result_file, default=lambda o: encoder(o))\r\n",
    "result_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}